{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File structure: This file is organized into 4 key sections:\n",
    "* Section 1: Data structure definitions and inits\n",
    "* Section 2: Function definitions for all primary functions\n",
    "* Section 3: Function definitions for various helper functions\n",
    "* Section 4: _main (invoking the primary function to price a basket), also functions to support sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: This is where we define and initialize data structures, import data from files, and load the various packages necessary for the computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "get_ipython().magic('reset -sf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from statsmodels.stats.correlation_tools import corr_nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the data structures that would be required for the calculation\n",
    "\n",
    "cds_data =  [\n",
    "            [31.80, 35.85,39.92,45.07,51.86],\n",
    "            [37.92,  42.81, 49.14,54.96,63.65],\n",
    "            [41.77, 47.96, 53.30,58.93,65.06],\n",
    "            [31.21, 36.79, 41.16,45.52,51.97],\n",
    "            [33.00, 39.36,44.65,49.26,57.61],\n",
    "            ]\n",
    "CDS5Y = pd.DataFrame(cds_data)\n",
    "CDS5Y_transposed = CDS5Y.transpose()\n",
    "\n",
    "corr_data_pearson = [\n",
    "            [1.000000, 0.874067, 0.830036, 0.917487, 0.849246],\n",
    "            [0.874067, 1.000000, 0.814210, 0.878369, 0.828025],\n",
    "            [0.830036, 0.814210, 1.000000, 0.835791, 0.860827],\n",
    "            [0.917487, 0.878369, 0.835791, 1.000000, 0.863615],\n",
    "            [0.849246, 0.828025, 0.860827, 0.863615, 1.000000]\n",
    "            ]\n",
    "\n",
    "corr_pearson = pd.DataFrame(corr_data_pearson)\n",
    "corr_data_kendall = [\n",
    "            [1.000000, 0.884988, 0.830244, 0.916459, 0.859054],\n",
    "            [0.884988, 1.000000, 0.823408, 0.885704, 0.847208],\n",
    "            [0.830244, 0.823408, 1.000000, 0.835718, 0.870892],\n",
    "            [0.916459, 0.885704, 0.835718, 1.000000, 0.871201],\n",
    "            [0.859054, 0.847208, 0.870892, 0.871201, 1.000000]\n",
    "            ]\n",
    "corr_kendall = pd.DataFrame(corr_data_kendall)\n",
    "\n",
    "\n",
    "L = 0.6 # recovery rate of 40%\n",
    "delta_t = 1\n",
    "DF = [0.998801438, 0.997405061, 0.995215319, 0.991248188, 0.986116836]\n",
    "deg_of_freedom = 3\n",
    "no_of_sims = 100000\n",
    "rand_num_type = 'sobol'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Primary function definitions (8 functions). Primary functions are those that perform significant computations such as simulating a Gaussian Copula. The subsequent section (Section 3) contains the definitions for the helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform sensitivity analysis - for stressed spreads, correlations and recovery rates\n",
    "\n",
    "def calculate_stressed_spreads(is_stressed_spreads, is_stressed_corr, is_stressed_L):\n",
    "    stressed_spreads = [.10, .20, .30, .40, .50]\n",
    "    stressed_corr = [-.40, -.30, -.20, -.10, .02, .04, .06]\n",
    "    stressed_L = [.4, .5, .6, .7, .8, .9]\n",
    "    result_gaussian = []\n",
    "    result_t = []   \n",
    "    \n",
    "    if (is_stressed_spreads):\n",
    "        for x in stressed_spreads:\n",
    "            result_gaussian.append(calculate_spreads('gaussian', 'spread', x, 0, 'default_rand_num_type')) \n",
    "            result_t.append(calculate_spreads('t', 'spread', x, 0, 'default_rand_num_type'))\n",
    "        return result_gaussian, result_t\n",
    "    \n",
    "    if (is_stressed_corr):\n",
    "        for x in stressed_corr:\n",
    "            result_gaussian.append(calculate_spreads('gaussian', 'corr', x, 0, 'default_rand_num_type')) \n",
    "            result_t.append(calculate_spreads('t', 'corr', x, 0, 'default_rand_num_type'))\n",
    "        return result_gaussian, result_t\n",
    "    \n",
    "    if (is_stressed_L):\n",
    "        for x in stressed_L:\n",
    "            result_gaussian.append(calculate_spreads('gaussian', 'L', x, 0, 'default_rand_num_type')) \n",
    "            result_t.append(calculate_spreads('t', 'L', x, 0, 'default_rand_num_type'))\n",
    "        return result_gaussian, result_t   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to assess convergence as a function of number of sims - for both pseudo-random numbers and sobol sequences\n",
    "\n",
    "def test_convergence():\n",
    "    num_sims = [1000, 5000, 10000, 25000, 50000, 75000, 100000]\n",
    "    result_gaussian_pseudo_random = []\n",
    "    result_gaussian_sobol = []\n",
    "    result_t_pseudo_random = []\n",
    "    result_t_sobol = []\n",
    "    \n",
    "    for x in num_sims:\n",
    "        result_gaussian_pseudo_random.append(calculate_spreads('gaussian', 'nostress', 0, x, 'pseudo_random'))\n",
    "        result_gaussian_sobol.append(calculate_spreads('gaussian', 'nostress', 0, x, 'sobol'))\n",
    "        result_t_pseudo_random.append(calculate_spreads('t', 'nostress', 0, x, 'pseudo_random'))\n",
    "        result_t_sobol.append(calculate_spreads('t', 'nostress', 0, x, 'sobol'))   \n",
    "                              \n",
    "    return result_gaussian_pseudo_random, result_gaussian_sobol, result_t_pseudo_random, result_t_sobol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spread calculation for k = 1 to 5\n",
    "\n",
    "def calculate_spreads(copula_type, stress_type, stress_size, num_sims, random_num_type):\n",
    "    \n",
    "    spreads = []\n",
    "    df2 = pd.DataFrame()\n",
    "    global CDS5Y_transposed, corr_pearson, corr_kendall, L, no_of_sims, rand_num_type\n",
    "    \n",
    "    if (num_sims != 0):\n",
    "        no_of_sims = num_sims\n",
    "        rand_num_type = random_num_type\n",
    "        \n",
    "    if(stress_type == 'spread'):\n",
    "        CDS5Y = pd.DataFrame(cds_data)\n",
    "        CDS5Y_transposed = CDS5Y.transpose()\n",
    "        CDS5Y_transposed = CDS5Y_transposed.apply(lambda x: x * (1 + stress_size))\n",
    "    elif(stress_type == 'corr' and copula_type == \"gaussian\"):\n",
    "        corr_pearson = pd.DataFrame(corr_data_pearson)\n",
    "        corr_pearson = corr_pearson.apply(lambda x: x * (1 + stress_size))\n",
    "        arr = np.array(corr_pearson)\n",
    "        np.fill_diagonal(arr, 1)\n",
    "        corr_pearson = pd.DataFrame(arr)\n",
    "    elif(stress_type == 'corr' and copula_type == \"t\"):\n",
    "        corr_kendall = pd.DataFrame(corr_data_kendall)\n",
    "        corr_kendall = corr_kendall.apply(lambda x: x * (1 + stress_size))\n",
    "        arr = np.array(corr_kendall)\n",
    "        np.fill_diagonal(arr, 1)\n",
    "        corr_kendall = pd.DataFrame(arr)\n",
    "    elif(stress_type == 'L'):\n",
    "        L = stress_size\n",
    "\n",
    "    if(copula_type == 'gaussian'):\n",
    "        df = pd.DataFrame(simulate_gaussian_copula())\n",
    "    else:\n",
    "        df = pd.DataFrame(simulate_t_copula())\n",
    "    df.columns =['BAC', 'CITI', 'GS', 'JPMC', 'MS'] \n",
    "              \n",
    "    for k in range (5):     \n",
    "        df['def_flag'] = (df.apply(lambda x: generate_def_flag(x.BAC, x.CITI, x.GS, x.JPMC, x.MS, k+1), axis=1))\n",
    "        df['def_time'] = (df.apply(lambda x: generate_def_time(x.BAC, x.CITI, x.GS, x.JPMC, x.MS, x.def_flag, k+1), axis=1))\n",
    "        df['def_payout'] = (df.apply(lambda x: generate_def_payout(x.BAC, x.CITI, x.GS, x.JPMC, x.MS, x.def_flag, x.def_time, k+1), axis=1))\n",
    "        df['prem_payout'] = (df.apply(lambda x: generate_prem_payout(x.def_flag, x.def_time), axis=1))\n",
    "        spread = (df['def_payout'].sum()/df['prem_payout'].sum())*10000\n",
    "        spreads.append(spread)\n",
    "        #df.to_csv(str(k)+'sim_results.csv')\n",
    "    return(spreads)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling from a simulated gaussian copula\n",
    "\n",
    "def simulate_gaussian_copula():\n",
    "    # sampling from a simulated gaussian copula\n",
    "    \n",
    "    if (rand_num_type == 'sobol'):\n",
    "        rand_normal = np.array(pd.read_csv (\"C:/Users/anirbighosh/Documents/CQF/Final Project/data files/sobol.csv\", header = None, nrows = no_of_sims)) \n",
    "    else:\n",
    "        rand_normal = np.array(pd.read_csv (\"C:/Users/anirbighosh/Documents/CQF/Final Project/data files/pseudo_random.csv\", header = None, nrows = no_of_sims)) \n",
    "      \n",
    "    rand_correlated = np.transpose(np.dot(calculate_cholesky_matrix(corr_pearson), np.transpose(rand_normal)))\n",
    "    rand_uniform = pd.DataFrame(norm.cdf(rand_correlated))\n",
    "    final_input = rand_uniform.apply(lambda x: abs(np.log(1-x)))\n",
    "\n",
    "    # cumulative hazard rates per entity\n",
    "    lambda_cum = genarate_cum_hazard_rates(CDS5Y_transposed)\n",
    "    final_lambdas = lambda_cum.transpose()\n",
    "\n",
    "    # calling  the get_def_time function recursively to estimate default times for all the 5 entities \n",
    "    def_time_all = []\n",
    "    for i in range(5):\n",
    "        def_time_all.append(get_def_time(final_input[i], final_lambdas[i]))\n",
    "    result = np.array(def_time_all).transpose()\n",
    "    \n",
    "    #final_lambdas.to_csv(str(L) + 'sim_results.csv')\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling from a simulated \"t\" copula\n",
    "\n",
    "def simulate_t_copula():\n",
    "    \n",
    "    if (rand_num_type == 'sobol'):\n",
    "        rand_normal = np.array(pd.read_csv (\"C:/Users/anirbighosh/Documents/CQF/Final Project/data files/sobol.csv\", header = None, nrows = no_of_sims))       \n",
    "    else:\n",
    "        rand_normal = np.array(pd.read_csv (\"C:/Users/anirbighosh/Documents/CQF/Final Project/data files/pseudo_random.csv\", header = None, nrows = no_of_sims)) \n",
    "    \n",
    "    rand_chisq = pd.read_csv (\"C:/Users/anirbighosh/Documents/CQF/Final Project/data files/chisq.csv\", header = None, nrows = no_of_sims)\n",
    "    #rand_chisq = pd.DataFrame(np.random.chisquare(deg_of_freedom, size=(len(rand_normal),5)))\n",
    "    rand_chisq_mod = rand_chisq.apply(lambda x: np.sqrt(x/deg_of_freedom))\n",
    "    rand_t = np.divide(rand_normal, np.array(rand_chisq_mod))\n",
    "    rand_correlated = np.transpose(np.dot(calculate_cholesky_matrix(corr_kendall), np.transpose(rand_t)))\n",
    "    rand_uniform = pd.DataFrame(t.cdf(rand_correlated, deg_of_freedom))\n",
    "    final_input = rand_uniform.apply(lambda x: abs(np.log(1-x)))\n",
    "\n",
    "    # cumulative hazard rates per entity\n",
    "    lambda_cum = genarate_cum_hazard_rates(CDS5Y_transposed)\n",
    "    final_lambdas = lambda_cum.transpose()\n",
    "\n",
    "    # calling  the get_def_time function recursively to estimate default times for all the 5 entities \n",
    "    def_time_all = []\n",
    "    for i in range(5):\n",
    "        def_time_all.append(get_def_time(final_input[i], final_lambdas[i]))\n",
    "    result = np.array(def_time_all).transpose()\n",
    "\n",
    "    return result\n",
    "    #pd.DataFrame(rand_correlated).to_csv('t_sim_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the final cumulative lambda matrix necessary for estimating default times\n",
    "\n",
    "def genarate_cum_hazard_rates(CDS5Y_transposed):\n",
    "    # generating the fullsurv prob matrix\n",
    "    surv_probs_all = []\n",
    "    for i in range(5):\n",
    "        surv_probs_all.append(calculate_surv_probs(CDS5Y_transposed[i]))\n",
    "    result = pd.DataFrame(surv_probs_all).transpose()    \n",
    "    #print(result)\n",
    "\n",
    "    #generating the hazard rate matrix\n",
    "    hazard_rates = result.apply(lambda x: -(np.log(x/x.shift(1)))).transpose()\n",
    "    hazard_rates.drop(hazard_rates.columns[[0]], axis = 1, inplace = True) \n",
    "    #print(hazard_rates)\n",
    "\n",
    "    # generating the cum hazard rate matrix\n",
    "    cum_hazard_rates = hazard_rates.assign(sum1 = lambda x: (x[1]), sum2 = lambda x: (x[1])+(x[2]), sum3 = lambda x: (x[1])+(x[2])+(x[3]), sum4 = lambda x: (x[1])+(x[2])+(x[3])+(x[4]), sum5 = lambda x: (x[1])+(x[2])+(x[3])+(x[4])+(x[5]) )\n",
    "    cum_hazard_rates.drop(cum_hazard_rates.columns[[0,1,2,3,4]], axis = 1, inplace = True)\n",
    "\n",
    "    return cum_hazard_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrapping piece-wise hazard rates (based on Professor Pena's additional notes on bootstrapping)\n",
    "\n",
    "def calculate_surv_probs(CDS5Y):\n",
    "    surv_probs = []\n",
    "    surv_probs.append(1)\n",
    "\n",
    "    for j in (0,1,2,3,4):\n",
    "\n",
    "        if j == 0:\n",
    "            prob_t1 = L/(L + delta_t * CDS5Y[0]/10000)\n",
    "            surv_probs.append(prob_t1)\n",
    "            #print(surv_probs)      \n",
    "        if j == 1:\n",
    "            #print(\"inside j = 1\")\n",
    "            first_term =  get_first_term(CDS5Y, surv_probs, j)\n",
    "            denominator = get_denominator(CDS5Y, surv_probs, j)\n",
    "            last_term = get_last_term(CDS5Y, surv_probs, j)\n",
    "            recurring_term = (first_term)\n",
    "            surv_prob = (recurring_term/denominator) + last_term\n",
    "            surv_probs.append(surv_prob)\n",
    "            #print(surv_probs)\n",
    "        if j == 2:\n",
    "            #print(\"inside j = 2\")\n",
    "            first_term =  get_first_term(CDS5Y, surv_probs, j)\n",
    "            second_term = get_second_term(CDS5Y, surv_probs, j)\n",
    "            denominator = get_denominator(CDS5Y, surv_probs, j)\n",
    "            last_term = get_last_term(CDS5Y, surv_probs, j)\n",
    "            recurring_term = (first_term + second_term)\n",
    "            surv_prob = recurring_term/denominator + last_term\n",
    "            surv_probs.append(surv_prob)\n",
    "            #print(surv_probs)\n",
    "        if j == 3:\n",
    "            #print(\"inside j = 3\")\n",
    "            first_term =  get_first_term(CDS5Y, surv_probs, j)\n",
    "            second_term = get_second_term(CDS5Y, surv_probs, j)\n",
    "            third_term =  get_third_term(CDS5Y, surv_probs, j)\n",
    "            denominator = get_denominator(CDS5Y, surv_probs, j)\n",
    "            last_term = get_last_term(CDS5Y, surv_probs, j)\n",
    "            recurring_term = (first_term + second_term + third_term)\n",
    "            surv_prob = recurring_term/denominator + last_term\n",
    "            surv_probs.append(surv_prob)\n",
    "            #print(surv_probs)\n",
    "        if j == 4:\n",
    "            #print(\"inside j = 4\")\n",
    "            first_term =  get_first_term(CDS5Y, surv_probs, j)\n",
    "            second_term = get_second_term(CDS5Y, surv_probs, j)\n",
    "            third_term =  get_third_term(CDS5Y, surv_probs, j)\n",
    "            fourth_term = get_fourth_term(CDS5Y, surv_probs, j)\n",
    "            denominator = get_denominator(CDS5Y, surv_probs, j)\n",
    "            last_term = get_last_term(CDS5Y, surv_probs, j)\n",
    "            recurring_term = (first_term + second_term + third_term + fourth_term)\n",
    "            surv_prob = recurring_term/denominator + last_term\n",
    "            surv_probs.append(surv_prob)\n",
    "            #print(surv_probs)\n",
    "            \n",
    "    return surv_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the cholesky matrix\n",
    "\n",
    "def calculate_cholesky_matrix(corr):\n",
    "\n",
    "    # decomposing the matrix using cholesky\n",
    "    if is_pos_def(corr):\n",
    "        corr_decomp = np.linalg.cholesky(corr) \n",
    "        return corr_decomp \n",
    "    else:\n",
    "        corr_near = corr_nearest(corr, threshold=1e-15, n_fact=100)\n",
    "        corr_decomp = np.linalg.cholesky(corr_near) \n",
    "        return corr_decomp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Helper function definitions (12 functions as of now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate def_flag\n",
    "\n",
    "def generate_def_flag(tau1, tau2, tau3, tau4, tau5, k):\n",
    "    tau_list = []\n",
    "    tau_list.extend([tau1, tau2, tau3, tau4, tau5])\n",
    "    total_def=sum(1 for item in tau_list if (item<5))\n",
    "    if total_def >= k:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate def_time\n",
    "\n",
    "def generate_def_time (tau1, tau2, tau3, tau4, tau5, def_flag, k):\n",
    "    tau_list = []\n",
    "    tau_list.extend([tau1, tau2, tau3, tau4, tau5])\n",
    "    tau_list_sorted = sorted (tau_list)\n",
    "    if def_flag == 1:\n",
    "        return max(tau_list_sorted[k-1], 0.25)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate def_payout\n",
    "\n",
    "def generate_def_payout (tau1, tau2, tau3, tau4, tau5, def_flag, def_time, k):\n",
    "    expected_loss = 0.2\n",
    "    \n",
    "    if def_flag == 1:\n",
    "        return expected_loss*L*get_DF(def_time)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate prem_payout (this is based on the simplified formula in Dr. Richard Diamond's notes - Pg 52)\n",
    "\n",
    "def generate_prem_payout (def_flag, def_time):\n",
    "    expected_loss = [1, 1, 1, 1, 1]\n",
    "       \n",
    "    if def_flag == 1:\n",
    "        return get_DF(def_time)*def_time\n",
    "    else:\n",
    "        return np.dot(expected_loss, DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate DF\n",
    "\n",
    "def get_DF(def_time):\n",
    "    coeff_a = 0.0093\n",
    "    coeff_b = 0.147\n",
    "    coeff_c = 0.124\n",
    "    int_rate = coeff_a*(def_time**2) + coeff_b*def_time + coeff_c\n",
    "    DF = 1/((1+int_rate/100)**def_time)\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to test if a correlation matrix is positive definite\n",
    "\n",
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate default times from simulated uniform random numbers (using accrual method)\n",
    "\n",
    "def get_def_time (sims, lambdas):\n",
    "    def_time = np.array([999.0]*len(sims))\n",
    "    for iterator1, x in enumerate(sims):\n",
    "        for iterator2, y in enumerate(lambdas):\n",
    "            if x < y:\n",
    "                def_time[iterator1] =  iterator2 + 0.5\n",
    "                break\n",
    "    return def_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the first term in the surv prob matrix\n",
    "\n",
    "def get_first_term(CDS5Y, surv_probs, j):     \n",
    "    first_term = DF[0] * ((L * surv_probs[0]) - (L + delta_t * CDS5Y[j]/10000)*surv_probs[1])\n",
    "    return first_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the second term in the surv prob matrix\n",
    "\n",
    "def get_second_term(CDS5Y, surv_probs, j):  \n",
    "    second_term = DF[1] * ((L * surv_probs[1]) - (L + delta_t * CDS5Y[j]/10000)*surv_probs[2])\n",
    "    return second_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the third term in the surv prob matrix\n",
    "\n",
    "def get_third_term(CDS5Y, surv_probs, j):  \n",
    "    third_term = DF[2] * ((L * surv_probs[2]) - (L + delta_t * CDS5Y[j]/10000)*surv_probs[3])\n",
    "    return third_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the fourth term in the surv prob matrix\n",
    "\n",
    "def get_fourth_term(CDS5Y, surv_probs, j):  \n",
    "    third_term = DF[3] * ((L * surv_probs[3]) - (L + delta_t * CDS5Y[j]/10000)*surv_probs[4])\n",
    "    return third_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the denominator term in the surv prob matrix\n",
    "\n",
    "def get_denominator(CDS5Y, surv_probs, j):\n",
    "    denominator = DF[j] * (L + delta_t * CDS5Y[j]/10000)\n",
    "    return denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the last term in the surv prob matrix\n",
    "\n",
    "def get_last_term(CDS5Y, surv_probs, j):\n",
    "    last_term = (surv_probs[j] * L) / (L + delta_t * CDS5Y[j]/10000)\n",
    "    return last_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4: This is where the simulations can be run and outputs generated. Code is provided for 3 use cases: a) calculating spreads (k= 1 to 5) under both the gaussian and 't' copulae, b) calculating spreads after shocking spreads, correlations and recovery rates, and c) assessing convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following functions for calculating spreads under both the guassian and \"t\" copulae\n",
    "\n",
    "#calculate_spreads('gaussian', 'nostress', 0, 0, 'default_random_num_type')\n",
    "#calculate_spreads('t', 'nostress', 0, 0, 'default_random_num_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following function for assessing convergence as a function of the number of simulations\n",
    "\n",
    "#test_convergence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following function for calcuating stressed spreads (stressing spreads, correlations and recovery rates)\n",
    "# set first param - True for stressing spreads, all others to False\n",
    "# set second param - True for stressing corr, all others to False\n",
    "# set thirs param - True for stressing recovery rates, all others to False\n",
    "\n",
    "# calculate_stressed_spreads(False, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for random number generation. Note that the random numbers are stored and read from a file - \n",
    "# this was done to facilitate debugging. This was also done since I was not able to find a robust sobol generator in Python, \n",
    "# hence the data was generated using R and stored in a file. If the random numbers need to generated run-time\n",
    "# (except sobol), the random number generation codes in \"simulate\" functions above needs to be uncommented.\n",
    "\n",
    "\n",
    "#rand_chisq = pd.DataFrame(np.random.chisquare(2, size=(100000,5)))\n",
    "#rand_chisq.to_csv('chisq.csv')\n",
    "#rand_normal = pd.DataFrame(np.random.normal(0, 1, size=(100000,5)))\n",
    "#rand_normal.to_csv('pseudo_random.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
